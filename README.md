# LASSI Code Evaluation

This is a sub-set of the LASSI framework to focus only on evaluating the code generated by a LASSI pipeline compared to the source code.


## Related documents

Become familiar with the folloing reference documents to better inform your human-in-the-loop review of this LLM-driven code evaluation process.

1. Original LASSI paper:
https://ieeexplore.ieee.org/document/10740822 

M. T. Dearing, Y. Tao, X. Wu, Z. Lan and V. Taylor, "LASSI: An LLM-Based Automated Self-Correcting Pipeline for Translating Parallel Scientific Codes," 2024 IEEE International Conference on Cluster Computing Workshops (CLUSTER Workshops), Kobe, Japan, 2024, pp. 136-143, doi: 10.1109/CLUSTERWorkshops61563.2024.00029.


2. C++ programming Guide by NVIDIA:
https://docs.nvidia.com/cuda/cuda-c-programming-guide/


3. CUDA C++ Best Practices Guide by NVIDIA:
https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/


## Getting Starting

The LASSI Code Evaluation tool is available as a public repository.

**Linux**

Starting in a local directory on your machine where you would like to install LASSI Code Eval:

```git clone https://github.com/SPEAR-UIC/CodeGreen.git```

```cd lassi-code-eval```

Create a local Python virtual environment, e.g., called ".env":

```python3 -m venv .env```

```source .env/bin/activate```

```pip install -r requirements.txt```

Launch Jupyter Lab to interact with the notebook:

```jupyter-lab```


